{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df = pd.read_csv(\"data/incidents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.isna().sum() / incidents_df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dtype(x):\n",
    "    if not x:\n",
    "        return np.NaN\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        print(f\"Wrong type (removed): {x}\")\n",
    "        return \"syntactically wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df = pd.read_csv(\n",
    "    \"data/incidents.csv\",\n",
    "    converters={\n",
    "        \"n_participants_child\": convert_dtype,\n",
    "        \"n_participants_teen\": convert_dtype,\n",
    "        \"n_participants_adult\": convert_dtype,\n",
    "        \"min_age_participants\": convert_dtype,\n",
    "        \"avg_age_participants\": convert_dtype,\n",
    "        \"max_age_participants\": convert_dtype,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_df = pd.read_csv(\"data/povertyByStateYear.csv\")\n",
    "\n",
    "poverty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_house_df = pd.read_csv(\"data/year_state_district_house.csv\")\n",
    "district_house_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntactic accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_type_vars = [\n",
    "    \"n_participants_child\",\n",
    "    \"n_participants_teen\",\n",
    "    \"n_participants_adult\",\n",
    "    \"min_age_participants\",\n",
    "    \"avg_age_participants\",\n",
    "    \"max_age_participants\",\n",
    "]\n",
    "\n",
    "for var in wrong_type_vars:\n",
    "    print(var)\n",
    "    print(\n",
    "        incidents_df.loc[incidents_df[var] == \"syntactically wrong\"].shape[0]\n",
    "        / incidents_df.shape[0]\n",
    "        * 100\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can change these error to NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in wrong_type_vars:\n",
    "    incidents_df.loc[incidents_df[var] == \"syntactically wrong\", var] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df[\"participant_age_group1\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.insert(\n",
    "    1, \"year\", [int(incidents_df[\"date\"][i][0:4]) for i in range(incidents_df.shape[0])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of incidents with a wrong date. For the moment, we consider these years as missing values, but we keep the information about the date, which will be useful to try to correct the year of the incident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    incidents_df.loc[incidents_df[\"year\"] > 2018, \"year\"].shape[0]\n",
    "    / incidents_df.shape[0]\n",
    "    * 100\n",
    ")\n",
    "print(\n",
    "    incidents_df.loc[incidents_df[\"year\"] < 2013, \"year\"].shape[0]\n",
    "    / incidents_df.shape[0]\n",
    "    * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.loc[incidents_df[\"year\"] > 2018, \"year\"] = np.NaN\n",
    "incidents_df.loc[incidents_df[\"year\"] < 2013, \"year\"] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also verify that in 2018 recordings stop on March 31st."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = incidents_df.loc[incidents_df[\"year\"] == 2018]\n",
    "tdf.sort_values(\"date\").tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if there are negative values for variables that we expect to be non-negative. \n",
    "We also want to remove improbable (too large) age values. We symbolically consider the maximum acceptable age to be 116, which is the oldest man on Earth's age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_negative_vars = [\n",
    "    \"congressional_district\",\n",
    "    \"state_house_district\",\n",
    "    \"state_senate_district\",\n",
    "    \"participant_age1\",\n",
    "    \"min_age_participants\",\n",
    "    \"avg_age_participants\",\n",
    "    \"max_age_participants\",\n",
    "    \"n_participants_child\",\n",
    "    \"n_participants_teen\",\n",
    "    \"n_participants_adult\",\n",
    "    \"n_males\",\n",
    "    \"n_females\",\n",
    "    \"n_killed\",\n",
    "    \"n_injured\",\n",
    "    \"n_arrested\",\n",
    "    \"n_unharmed\",\n",
    "    \"n_participants\",\n",
    "]\n",
    "\n",
    "age_vars = [\n",
    "    \"participant_age1\",\n",
    "    \"min_age_participants\",\n",
    "    \"avg_age_participants\",\n",
    "    \"max_age_participants\",\n",
    "]\n",
    "\n",
    "for var in non_negative_vars:\n",
    "    print(var)\n",
    "    tmp = incidents_df.loc[incidents_df[var].notna()]\n",
    "    if var in age_vars:\n",
    "        print(\n",
    "            tmp.loc[tmp[var] < 0].shape[0] / incidents_df.shape[0] * 100\n",
    "            + tmp.loc[tmp[var] > 116].shape[0] / incidents_df.shape[0] * 100\n",
    "        )\n",
    "        incidents_df.loc[incidents_df[var] < 0, var] = np.NaN\n",
    "        incidents_df.loc[incidents_df[var] > 116, var] = np.NaN\n",
    "    else:\n",
    "        print(tmp.loc[tmp[var] < 0].shape[0] / incidents_df.shape[0] * 100)\n",
    "        incidents_df.loc[incidents_df[var] < 0, var] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other variables that should be constrained in a specific range are coordinates. Now, to be precise we should check that all coordinates match the respsective county or city, but here we just investigate cases where coordinates are not in the USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(incidents_df[\"latitude\"]))\n",
    "print(np.max(incidents_df[\"latitude\"]))\n",
    "print(np.min(incidents_df[\"longitude\"]))\n",
    "print(np.max(incidents_df[\"longitude\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.loc[incidents_df[\"longitude\"] > -60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.loc[incidents_df[\"longitude\"] > -60, \"longitude\"] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, there are only 5 cases where the longitude attribute seems wrong. So we can try to check if changing the sign of the longitude is consistent with the rest of the information on the location.\n",
    "\n",
    "Using google maps, we verify that all the 5 locations match if the lognitude's sign is reverse. Moreover, these 5 incidents are all TSA Actions in different airports.\n",
    "\n",
    "We can now correct the coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.loc[incidents_df[\"longitude\"] > -60, \"longitude\"] = -incidents_df.loc[\n",
    "    incidents_df[\"longitude\"] > -60, \"longitude\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_notna = incidents_df.loc[incidents_df[\"min_age_participants\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"max_age_participants\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"avg_age_participants\"].notna()]\n",
    "\n",
    "tmp = tmp_notna.loc[\n",
    "    tmp_notna[\"max_age_participants\"] >= tmp_notna[\"avg_age_participants\"]\n",
    "]\n",
    "tmp = tmp.loc[tmp[\"min_age_participants\"] <= tmp[\"participant_age1\"]]\n",
    "\n",
    "tmp.shape[0] / tmp_notna.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_notna = incidents_df.loc[incidents_df[\"min_age_participants\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"max_age_participants\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"participant_age1\"].notna()]\n",
    "\n",
    "tmp = tmp_notna.loc[tmp_notna[\"max_age_participants\"] >= tmp_notna[\"participant_age1\"]]\n",
    "tmp = tmp.loc[tmp[\"min_age_participants\"] <= tmp[\"participant_age1\"]]\n",
    "\n",
    "tmp.shape[0] / tmp_notna.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check that the number of a special categrory of participants if not larger than the total number of participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\n",
    "    \"n_killed\",\n",
    "    \"n_injured\",\n",
    "    \"n_unharmed\",\n",
    "    \"n_arrested\",\n",
    "    \"n_participants_child\",\n",
    "    \"n_participants_teen\",\n",
    "    \"n_participants_adult\",\n",
    "    \"n_males\",\n",
    "    \"n_females\",\n",
    "]:\n",
    "    print(col)\n",
    "    tmp_notna = incidents_df.loc[incidents_df[col].notna()]\n",
    "    tmp = tmp_notna.loc[tmp_notna[col] > tmp_notna[\"n_participants\"]]\n",
    "\n",
    "    print(tmp.shape[0] / tmp_notna.shape[0] * 100)\n",
    "\n",
    "    incidents_df[col][tmp.index] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing that we may want to check is the information about the number of participants.\n",
    "We expect the fllowing equalities to hold:\n",
    "* n_participants = n_males + n_females \n",
    "* n_participants = n_participants_child + n_participants_teen + n_participants_adult\n",
    "* n_participants = n_killed + n_unharmed + n_injured \n",
    "or\n",
    "* n_participants = n_killed + n_unharmed + n_injured + n_arrested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_notna = incidents_df.loc[incidents_df[\"n_killed\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_injured\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_unharmed\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_arrested\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_participants\"].notna()]\n",
    "\n",
    "tmp = tmp_notna.loc[\n",
    "    tmp_notna[\"n_killed\"]\n",
    "    + tmp_notna[\"n_injured\"]\n",
    "    + tmp_notna[\"n_unharmed\"]\n",
    "    + tmp_notna[\"n_arrested\"]\n",
    "    == tmp_notna[\"n_participants\"]\n",
    "]\n",
    "\n",
    "tmp.shape[0] / tmp_notna.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_notna = incidents_df.loc[incidents_df[\"n_participants_child\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_participants_teen\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_participants_adult\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_participants\"].notna()]\n",
    "\n",
    "tmp = tmp_notna.loc[\n",
    "    tmp_notna[\"n_participants_child\"]\n",
    "    + tmp_notna[\"n_participants_teen\"]\n",
    "    + tmp_notna[\"n_participants_adult\"]\n",
    "    == tmp_notna[\"n_participants\"]\n",
    "]\n",
    "\n",
    "tmp.shape[0] / tmp_notna.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_notna = incidents_df.loc[incidents_df[\"n_males\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_females\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_participants\"].notna()]\n",
    "\n",
    "tmp = tmp_notna.loc[\n",
    "    tmp_notna[\"n_males\"] + tmp_notna[\"n_females\"] == tmp_notna[\"n_participants\"]\n",
    "]\n",
    "\n",
    "tmp.shape[0] / tmp_notna.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if the count is not always correct, for now we keep the information about the group composition as it could still be useful. Also because it would be difficult to identify the incorrect value among the different attributes in the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.loc[incidents_df[\"n_participants\"] == 0].shape[0] / incidents_df.shape[\n",
    "    0\n",
    "] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in [\n",
    "    \"n_males\",\n",
    "    \"n_females\",\n",
    "    \"n_killed\",\n",
    "    \"n_injured\",\n",
    "    \"n_unharmed\",\n",
    "    \"n_arrested\",\n",
    "    \"n_participants_adult\",\n",
    "    \"n_participants_teen\",\n",
    "    \"n_participants_child\",\n",
    "]:\n",
    "    print(\n",
    "        incidents_df.loc[\n",
    "            (incidents_df[\"n_participants\"] == 0) & (incidents_df[var] > 0)\n",
    "        ].shape[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.loc[incidents_df[\"n_participants\"] == 0, \"n_participants\"] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(incidents_df.isnull().sum() / incidents_df.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = incidents_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"povertyPercentage\"] = \" \"\n",
    "joined_df[\"party\"] = \" \"\n",
    "joined_df[\"candidatevotes\"] = \" \"\n",
    "joined_df[\"totalvotes\"] = \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid dates: 1/1/2013 to 31/3/2018. \\\n",
    "there are a lot of incidents with wrong dates (2028-2030). \\\n",
    "Ho googlato un po' di notizie usando le note del dataset, le città ecc. e sembra che 2028->2013; 2029->2014; 2030->2015. (Non si possono controllare uno a uno perché sono migliaia, quindi ne estraiamo un po' a caso e ci fidiamo?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "for i in range(joined_df.shape[0]):\n",
    "    if int(joined_df[\"date\"][i][0:4]) > 2018:\n",
    "        joined_df[\"year\"][i] = int(joined_df[\"date\"][i][0:4]) - 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(joined_df.shape[0]):\n",
    "    povertyPercentage = poverty_df.loc[\n",
    "        (poverty_df[\"year\"] == joined_df.loc[i, \"year\"])\n",
    "        & (poverty_df[\"state\"] == joined_df.loc[i, \"state\"]),\n",
    "        \"povertyPercentage\",\n",
    "    ].values\n",
    "\n",
    "    if len(povertyPercentage) == 1:\n",
    "        joined_df[\"povertyPercentage\"][i] = povertyPercentage[0]\n",
    "    else:\n",
    "        joined_df[\"povertyPercentage\"][i] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congressional elections occur every 2 years!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(joined_df.shape[0]):\n",
    "    party = district_house_df.loc[\n",
    "        (district_house_df[\"year\"] // 2 == joined_df[\"year\"][i] // 2)\n",
    "        & (district_house_df[\"state\"] == joined_df[\"state\"][i].upper())\n",
    "        & (\n",
    "            district_house_df[\"congressional_district\"]\n",
    "            == joined_df[\"congressional_district\"][i]\n",
    "        ),\n",
    "        \"party\",\n",
    "    ].values\n",
    "\n",
    "    if len(party) == 1:\n",
    "        joined_df[\"party\"][i] = party[0]\n",
    "    else:\n",
    "        joined_df[\"party\"][i] = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(joined_df.shape[0]):\n",
    "    candidatevotes = district_house_df.loc[\n",
    "        (district_house_df[\"year\"] // 2 == joined_df.loc[i, \"year\"] // 2)\n",
    "        & (district_house_df[\"state\"] == joined_df.loc[i, \"state\"].upper())\n",
    "        & (\n",
    "            district_house_df[\"congressional_district\"]\n",
    "            == joined_df.loc[i, \"congressional_district\"]\n",
    "        ),\n",
    "        \"candidatevotes\",\n",
    "    ].values\n",
    "\n",
    "    if len(candidatevotes) == 1:\n",
    "        joined_df[\"candidatevotes\"][i] = candidatevotes[0]\n",
    "    else:\n",
    "        joined_df[\"candidatevotes\"][i] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(joined_df.shape[0]):\n",
    "    totalvotes = district_house_df.loc[\n",
    "        (district_house_df[\"year\"] // 2 == joined_df.loc[i, \"year\"] // 2)\n",
    "        & (district_house_df[\"state\"] == joined_df.loc[i, \"state\"].upper())\n",
    "        & (\n",
    "            district_house_df[\"congressional_district\"]\n",
    "            == joined_df.loc[i, \"congressional_district\"]\n",
    "        ),\n",
    "        \"totalvotes\",\n",
    "    ].values\n",
    "\n",
    "    if len(totalvotes) == 1:\n",
    "        joined_df[\"totalvotes\"][i] = totalvotes[0]\n",
    "    else:\n",
    "        joined_df[\"totalvotes\"][i] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.to_csv(\"data/joined_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = pd.read_csv(\"data/joined_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mean(series):\n",
    "    return series.dropna().mean()\n",
    "\n",
    "\n",
    "def custom_mode(series):\n",
    "    return series.dropna().mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"latitude\"].fillna(\n",
    "    joined_df.groupby([\"state\", \"city_or_county\"])[\"latitude\"].transform(custom_mean),\n",
    "    inplace=True,\n",
    ")\n",
    "joined_df[\"longitude\"].fillna(\n",
    "    joined_df.groupby([\"state\", \"city_or_county\"])[\"longitude\"].transform(custom_mean),\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have no info about city, we use states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"latitude\"].fillna(\n",
    "    joined_df.groupby([\"state\"])[\"latitude\"].transform(custom_mean),\n",
    "    inplace=True,\n",
    ")\n",
    "joined_df[\"longitude\"].fillna(\n",
    "    joined_df.groupby([\"state\"])[\"longitude\"].transform(custom_mean),\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"avg_age_participants\"].fillna(\n",
    "    custom_mean(joined_df[\"avg_age_participants\"]),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "joined_df[\"min_age_participants\"].fillna(\n",
    "    custom_mean(joined_df[\"min_age_participants\"]),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "joined_df[\"max_age_participants\"].fillna(\n",
    "    custom_mean(joined_df[\"max_age_participants\"]),\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"n_participants\"].fillna(\n",
    "    custom_mean(joined_df[\"n_participants\"]),\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "children/teen/adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = (\n",
    "    custom_mean(joined_df[\"n_participants_adult\"] / joined_df[\"n_participants\"])\n",
    "    + custom_mean(joined_df[\"n_participants_teen\"] / joined_df[\"n_participants\"])\n",
    "    + custom_mean(joined_df[\"n_participants_child\"] / joined_df[\"n_participants\"])\n",
    ")\n",
    "\n",
    "residual = 1 - tot\n",
    "\n",
    "avg_children_ratio = custom_mean(\n",
    "    joined_df[\"n_participants_child\"] / joined_df[\"n_participants\"]\n",
    ") * (1 + residual)\n",
    "avg_teen_ratio = custom_mean(\n",
    "    joined_df[\"n_participants_teen\"] / joined_df[\"n_participants\"]\n",
    ") * (1 + residual)\n",
    "\n",
    "joined_df[\"n_participants_child\"].fillna(\n",
    "    (avg_children_ratio * joined_df[\"n_participants\"]).astype(int), inplace=True\n",
    ")\n",
    "joined_df[\"n_participants_teen\"].fillna(\n",
    "    (avg_teen_ratio * joined_df[\"n_participants\"]).astype(int), inplace=True\n",
    ")\n",
    "joined_df[\"n_participants_adult\"].fillna(\n",
    "    (\n",
    "        joined_df[\"n_participants\"]\n",
    "        - (joined_df[\"n_participants_teen\"] + joined_df[\"n_participants_child\"])\n",
    "    ).astype(int),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "for i in range(joined_df.shape[0]):\n",
    "    joined_df[\"n_participants_adult\"][i] = joined_df[\"n_participants\"][i] - (\n",
    "        joined_df[\"n_participants_teen\"][i] + joined_df[\"n_participants_child\"][i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "males/females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = custom_mean(joined_df[\"n_males\"] / joined_df[\"n_participants\"]) + custom_mean(\n",
    "    joined_df[\"n_females\"] / joined_df[\"n_participants\"]\n",
    ")\n",
    "\n",
    "residual = 1 - tot\n",
    "\n",
    "avg_females_ratio = custom_mean(\n",
    "    joined_df[\"n_females\"] / joined_df[\"n_participants\"]\n",
    ") * (1 + residual)\n",
    "\n",
    "joined_df[\"n_females\"].fillna(\n",
    "    (avg_females_ratio * joined_df[\"n_participants\"]).astype(int), inplace=True\n",
    ")\n",
    "\n",
    "for i in range(joined_df.shape[0]):\n",
    "    joined_df[\"n_males\"][i] = joined_df[\"n_participants\"][i] - (\n",
    "        joined_df[\"n_females\"][i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "killed/injured/arrested/unharmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = (\n",
    "    custom_mean(joined_df[\"n_killed\"] / joined_df[\"n_participants\"])\n",
    "    + custom_mean(joined_df[\"n_injured\"] / joined_df[\"n_participants\"])\n",
    "    + custom_mean(joined_df[\"n_arrested\"] / joined_df[\"n_participants\"])\n",
    "    + custom_mean(joined_df[\"n_unharmed\"] / joined_df[\"n_participants\"])\n",
    ")\n",
    "\n",
    "residual = 1 - tot\n",
    "\n",
    "avg_killed_ratio = custom_mean(joined_df[\"n_killed\"] / joined_df[\"n_participants\"]) * (\n",
    "    1 + residual\n",
    ")\n",
    "avg_injured_ratio = custom_mean(\n",
    "    joined_df[\"n_injured\"] / joined_df[\"n_participants\"]\n",
    ") * (1 + residual)\n",
    "avg_arrested_ratio = custom_mean(\n",
    "    joined_df[\"n_arrested\"] / joined_df[\"n_participants\"]\n",
    ") * (1 + residual)\n",
    "\n",
    "joined_df[\"n_killed\"].fillna(\n",
    "    (avg_killed_ratio * joined_df[\"n_participants\"]).astype(int), inplace=True\n",
    ")\n",
    "joined_df[\"n_injured\"].fillna(\n",
    "    (avg_injured_ratio * joined_df[\"n_participants\"]).astype(int), inplace=True\n",
    ")\n",
    "joined_df[\"n_arrested\"].fillna(\n",
    "    (avg_arrested_ratio * joined_df[\"n_participants\"]).astype(int), inplace=True\n",
    ")\n",
    "for i in range(joined_df.shape[0]):\n",
    "    joined_df[\"n_unharmed\"][i] = joined_df[\"n_participants\"][i] - (\n",
    "        joined_df[\"n_killed\"][i]\n",
    "        + joined_df[\"n_injured\"][i]\n",
    "        + joined_df[\"n_arrested\"][i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. party and votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.loc[joined_df[\"party\"] == \" \"].shape[0] / joined_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.loc[joined_df[\"party\"] == \" \", \"party\"] = np.NaN\n",
    "joined_df.loc[joined_df[\"totalvotes\"] == 0, \"totalvotes\"] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"party\"].fillna(\n",
    "    joined_df.groupby([\"year\", \"state\"])[\"party\"].transform(custom_mode).values[0],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"totalvotes\"].fillna(\n",
    "    joined_df.groupby([\"year\", \"party\"])[\"totalvotes\"].transform(custom_mean),\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "avg_votes_ratio = custom_mean(joined_df[\"candidatevotes\"] / joined_df[\"totalvotes\"])\n",
    "\n",
    "joined_df[\"candidatevotes\"].fillna(\n",
    "    (joined_df[\"totalvotes\"] * avg_votes_ratio).astype(int),\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined_df.loc[joined_df[\"party\"] == \" \"].shape[0] / joined_df.shape[0])\n",
    "print(joined_df.loc[joined_df[\"totalvotes\"] == \" \"].shape[0] / joined_df.shape[0])\n",
    "print(joined_df.loc[joined_df[\"candidatevotes\"] == \" \"].shape[0] / joined_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove / modify attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.drop(\n",
    "    columns=[\n",
    "        \"address\",\n",
    "        \"city_or_county\",\n",
    "        \"congressional_district\",\n",
    "        \"state_house_district\",\n",
    "        \"state_senate_district\",\n",
    "        \"participant_age1\",\n",
    "        \"participant_age_group1\",\n",
    "        \"participant_gender1\",\n",
    "        \"notes\",\n",
    "        \"incident_characteristics1\",\n",
    "        \"incident_characteristics2\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.insert(\n",
    "    1,\n",
    "    \"month\",\n",
    "    [int(incidents_df[\"date\"][i][5:7]) for i in range(incidents_df.shape[0])],\n",
    ")\n",
    "\n",
    "joined_df = joined_df.drop(columns=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.insert(\n",
    "    23,\n",
    "    \"votes_ratio\",\n",
    "    [\n",
    "        joined_df[\"candidatevotes\"][i] / joined_df[\"totalvotes\"][i]\n",
    "        for i in range(incidents_df.shape[0])\n",
    "    ],\n",
    ")\n",
    "\n",
    "joined_df = joined_df.drop(columns=[\"candidatevotes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.loc[joined_df[\"n_participants\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.isna().sum() / joined_df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\n",
    "    [\n",
    "        \"min_age_participants\",\n",
    "        \"max_age_participants\",\n",
    "        \"n_participants_child\",\n",
    "        \"n_participants_teen\",\n",
    "        \"n_participants_adult\",\n",
    "        \"povertyPercentage\",\n",
    "    ]\n",
    "] = joined_df[\n",
    "    [\n",
    "        \"min_age_participants\",\n",
    "        \"max_age_participants\",\n",
    "        \"n_participants_child\",\n",
    "        \"n_participants_teen\",\n",
    "        \"n_participants_adult\",\n",
    "        \"povertyPercentage\",\n",
    "    ]\n",
    "].astype(\n",
    "    float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_normalize = [\n",
    "    \"n_arrested\",\n",
    "    \"n_unharmed\",\n",
    "    \"n_killed\",\n",
    "    \"n_injured\",\n",
    "    \"n_participants_adult\",\n",
    "    \"n_participants_teen\",\n",
    "    \"n_participants_child\",\n",
    "    \"n_males\",\n",
    "    \"n_females\",\n",
    "]\n",
    "\n",
    "# Normalize columns by dividing each element by n_participants\n",
    "joined_df[columns_to_normalize] = joined_df[columns_to_normalize].div(\n",
    "    joined_df[\"n_participants\"], axis=0\n",
    ")\n",
    "\n",
    "joined_df = joined_df.rename(\n",
    "    columns={\n",
    "        \"n_arrested\": \"arrested_ratio\",\n",
    "        \"n_unharmed\": \"unharmed_ratio\",\n",
    "        \"n_killed\": \"killed_ratio\",\n",
    "        \"n_injured\": \"injured_ratio\",\n",
    "        \"n_participants_adult\": \"adults_ratio\",\n",
    "        \"n_participants_teen\": \"teen_ratio\",\n",
    "        \"n_participants_child\": \"children_ratio\",\n",
    "        \"n_males\": \"males_ratio\",\n",
    "        \"n_females\": \"females_ratio\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.read_csv(\"data/population.csv\")\n",
    "population_df = population_df[[\"placeName\", \"Date:Count_Person\", \"Value:Count_Person\"]]\n",
    "population_df = population_df.astype({})\n",
    "population_df = population_df.rename(\n",
    "    columns={\n",
    "        \"placeName\": \"state\",\n",
    "        \"Date:Count_Person\": \"year\",\n",
    "        \"Value:Count_Person\": \"population\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"population\"] = \" \"\n",
    "\n",
    "for i in range(joined_df.shape[0]):\n",
    "    year_condition = population_df[\"year\"] == joined_df[\"year\"][i]\n",
    "    state_condition = population_df[\"state\"] == joined_df[\"state\"][i]\n",
    "    population = population_df.loc[\n",
    "        year_condition & state_condition, \"population\"\n",
    "    ].values\n",
    "\n",
    "    if len(population) == 1:\n",
    "        joined_df[\"population\"][i] = population[0]\n",
    "    else:\n",
    "        joined_df[\"population\"][i] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.to_csv(\"data/joined_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Variables distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"DEMOCRAT\": \"blue\",\n",
    "    \"DEMOCRATIC-FARMER-LABOR\": \"purple\",\n",
    "    \"REPUBLICAN\": \"red\",\n",
    "    \" \": \"gray\",\n",
    "}\n",
    "usa = plt.imread(\"images/NorthAmerica.png\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(18, 9))\n",
    "for i, y in enumerate([2012, 2014, 2016, 2018]):\n",
    "    axs[i // 2, i % 2].imshow(usa, extent=[-180, -60, 20, 80])\n",
    "    year_df = joined_df.loc[joined_df[\"year\"] // 2 == y // 2]\n",
    "    if y == 2012:\n",
    "        axs[i // 2, i % 2].set_title(f\"2013\", fontsize=20)\n",
    "    elif y == 2018:\n",
    "        axs[i // 2, i % 2].set_title(f\"2018\", fontsize=20)\n",
    "    else:\n",
    "        axs[i // 2, i % 2].set_title(f\"{y}-{y+1}\", fontsize=20)\n",
    "    axs[i // 2, i % 2].scatter(\n",
    "        [year_df[\"longitude\"][i] for i in year_df.index],\n",
    "        [year_df[\"latitude\"][i] for i in year_df.index],\n",
    "        s=3,\n",
    "        c=[colors[year_df[\"party\"][i]] for i in year_df.index],\n",
    "    )\n",
    "    axs[i // 2, i % 2].set_xlim([-180, -60])\n",
    "    axs[i // 2, i % 2].set_ylim([18, 75])\n",
    "    axs[i // 2, i % 2].plot([0], \"r\", label=\"REPUBLICAN\")\n",
    "    axs[i // 2, i % 2].plot([0], \"b\", label=\"DEMOCRAT\")\n",
    "    axs[i // 2, i % 2].plot([0], \"purple\", label=\"DEMOCRATIC-FARMER-LABOR\")\n",
    "    axs[i // 2, i % 2].plot([0], \"g\", label=\"unavailable\")\n",
    "    axs[i // 2, i % 2].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Generate a list of 50 random RGBA colors\n",
    "random_colors = [\n",
    "    (random.random(), random.random(), random.random(), random.uniform(0.5, 1.0))\n",
    "    for _ in range(51)\n",
    "]\n",
    "\n",
    "colors = {}\n",
    "state_list = list(joined_df.sort_values(\"state\", ascending=False)[\"state\"].unique())\n",
    "for i, state in enumerate(state_list):\n",
    "    colors[state] = random_colors[i]\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "usa = plt.imread(\"images/NorthAmerica.png\")\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    1,\n",
    "    2,\n",
    "    figsize=(30, 10),\n",
    "    gridspec_kw={\"height_ratios\": [1], \"width_ratios\": [1, 1]},\n",
    ")\n",
    "\n",
    "axs[0].imshow(usa, extent=[-180, -60, 20, 80])\n",
    "axs[0].scatter(\n",
    "    [joined_df[\"longitude\"][i] for i in joined_df.index],\n",
    "    [joined_df[\"latitude\"][i] for i in joined_df.index],\n",
    "    s=1,\n",
    "    c=[colors[joined_df[\"state\"][i]] for i in joined_df.index],\n",
    ")\n",
    "axs[0].set_xlim([-170, -65])\n",
    "axs[0].set_ylim([18, 80])\n",
    "\n",
    "for i, value in enumerate(\n",
    "    joined_df.sort_values(\"state\", ascending=False)[\"state\"].unique()\n",
    "):\n",
    "    count = joined_df.loc[joined_df[\"state\"] == value].shape[0]\n",
    "    axs[1].barh(value, count, color=random_colors[i])\n",
    "\n",
    "axs[1].set_xlabel(\"Number of incidents from Jan 2013 to Mar 2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poverty percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "usa = plt.imread(\"images/NorthAmerica.png\")\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    1,\n",
    "    2,\n",
    "    figsize=(30, 10),\n",
    "    gridspec_kw={\"height_ratios\": [1], \"width_ratios\": [1, 1]},\n",
    ")\n",
    "\n",
    "axs[0].imshow(usa, extent=[-180, -60, 20, 80])\n",
    "scatter = axs[0].scatter(\n",
    "    [joined_df[\"longitude\"][i] for i in joined_df.index],\n",
    "    [joined_df[\"latitude\"][i] for i in joined_df.index],\n",
    "    s=1,\n",
    "    c=[joined_df[\"povertyPercentage\"][i] for i in joined_df.index],\n",
    ")\n",
    "\n",
    "axs[0].set_xlim([-170, -60])\n",
    "axs[0].set_ylim([18, 80])\n",
    "\n",
    "####\n",
    "\n",
    "states = joined_df.sort_values(\"state\", ascending=False)[\"state\"].unique()\n",
    "incidents_rate = []\n",
    "\n",
    "poverty = []\n",
    "for i, value in enumerate(states):\n",
    "    poverty.append(\n",
    "        np.mean(joined_df.loc[joined_df[\"state\"] == value][\"povertyPercentage\"])\n",
    "    )\n",
    "\n",
    "sorted_indices = np.argsort(poverty)\n",
    "\n",
    "# Use sorted indices to reorder both arrays\n",
    "poverty = [poverty[i] for i in sorted_indices]\n",
    "states = [states[i] for i in sorted_indices]\n",
    "\n",
    "cmap = cm.magma\n",
    "norm = plt.Normalize(min(poverty), max(poverty))\n",
    "colors = cmap(norm(poverty))\n",
    "sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=axs[1], label=\"Poverty percentage\")\n",
    "\n",
    "for i, value in enumerate(states):\n",
    "    count = joined_df.loc[joined_df[\"state\"] == value].shape[0]\n",
    "    population = population_df[\n",
    "        (population_df[\"state\"] == value) & (population_df[\"year\"] == 2018)\n",
    "    ][\"population\"]\n",
    "    incidents_rate.append(count / population * 1e6)\n",
    "    axs[1].barh(value, count / population * 1e6, color=colors[i])\n",
    "\n",
    "axs[1].set_xlabel(\"Number of incidents every million people from Jan 2013 to Mar 2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pairwise correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    \"year\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"min_age_participants\",\n",
    "    \"avg_age_participants\",\n",
    "    \"max_age_participants\",\n",
    "    \"children_ratio\",\n",
    "    \"teen_ratio\",\n",
    "    \"adults_ratio\",\n",
    "    \"males_ratio\",\n",
    "    \"females_ratio\",\n",
    "    \"killed_ratio\",\n",
    "    \"injured_ratio\",\n",
    "    \"arrested_ratio\",\n",
    "    \"unharmed_ratio\",\n",
    "    \"n_participants\",\n",
    "    \"povertyPercentage\",\n",
    "    \"votes_ratio\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = joined_df[numerical_columns].corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    vmax=0.3,\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.5},\n",
    ")\n",
    "\n",
    "sns.set(font_scale=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = joined_df.copy()\n",
    "final_df.to_csv(\"data/final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isna().sum() / joined_df.shape[0] * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm-1svB9iq5-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
