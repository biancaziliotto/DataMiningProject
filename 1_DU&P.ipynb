{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6w/gs5ftqnj599ct2q_7plmjnk00000gn/T/ipykernel_51874/1719764553.py:1: DtypeWarning: Columns (15,16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  incidents_df = pd.read_csv(\"data/incidents.csv\")\n"
     ]
    }
   ],
   "source": [
    "incidents_df = pd.read_csv(\"data/incidents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.isna().sum() / incidents_df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dtype(x):\n",
    "    if not x:\n",
    "        return np.NaN\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        print(f\"Wrong type (removed): {x}\")\n",
    "        return \"syntactically wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df = pd.read_csv(\n",
    "    \"data/incidents.csv\",\n",
    "    converters={\n",
    "        \"n_participants_child\": convert_dtype,\n",
    "        \"n_participants_teen\": convert_dtype,\n",
    "        \"n_participants_adult\": convert_dtype,\n",
    "        \"min_age_participants\": convert_dtype,\n",
    "        \"avg_age_participants\": convert_dtype,\n",
    "        \"max_age_participants\": convert_dtype,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.shape[0] - incidents_df.drop_duplicates().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df = incidents_df.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poverty_df = pd.read_csv(\"data/povertyByStateYear.csv\")\n",
    "\n",
    "poverty_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_house_df = pd.read_csv(\"data/year_state_district_house.csv\")\n",
    "district_house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(incidents_df[\"congressional_district\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(incidents_df[\"congressional_district\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntactic accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_type_vars = [\n",
    "    \"n_participants_child\",\n",
    "    \"n_participants_teen\",\n",
    "    \"n_participants_adult\",\n",
    "    \"min_age_participants\",\n",
    "    \"avg_age_participants\",\n",
    "    \"max_age_participants\",\n",
    "]\n",
    "\n",
    "for var in wrong_type_vars:\n",
    "    print(var)\n",
    "    print(\n",
    "        incidents_df.loc[incidents_df[var] == \"syntactically wrong\"].shape[0]\n",
    "        / incidents_df.shape[0]\n",
    "        * 100\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can change these error to NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in wrong_type_vars:\n",
    "    incidents_df.loc[incidents_df[var] == \"syntactically wrong\", var] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df[\"participant_age_group1\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.insert(\n",
    "    1, \"year\", [int(incidents_df[\"date\"][i][0:4]) for i in range(incidents_df.shape[0])]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of incidents with a wrong date. For the moment, we consider these years as missing values, but we keep the information about the date, which will be useful to try to correct the year of the incident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    incidents_df.loc[incidents_df[\"year\"] > 2018, \"year\"].shape[0]\n",
    "    / incidents_df.shape[0]\n",
    "    * 100\n",
    ")\n",
    "print(\n",
    "    incidents_df.loc[incidents_df[\"year\"] < 2013, \"year\"].shape[0]\n",
    "    / incidents_df.shape[0]\n",
    "    * 100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.loc[incidents_df[\"year\"] > 2018, \"year\"] = np.NaN\n",
    "incidents_df.loc[incidents_df[\"year\"] < 2013, \"year\"] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also verify that in 2018 recordings stop on March 31st."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = incidents_df.loc[incidents_df[\"year\"] == 2018]\n",
    "tdf.sort_values(\"date\").tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if there are negative values for variables that we expect to be non-negative. \n",
    "We also want to remove improbable (too large) age values. We symbolically consider the maximum acceptable age to be 116, which is the oldest man on Earth's age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_negative_vars = [\n",
    "    \"congressional_district\",\n",
    "    \"state_house_district\",\n",
    "    \"state_senate_district\",\n",
    "    \"participant_age1\",\n",
    "    \"min_age_participants\",\n",
    "    \"avg_age_participants\",\n",
    "    \"max_age_participants\",\n",
    "    \"n_participants_child\",\n",
    "    \"n_participants_teen\",\n",
    "    \"n_participants_adult\",\n",
    "    \"n_males\",\n",
    "    \"n_females\",\n",
    "    \"n_killed\",\n",
    "    \"n_injured\",\n",
    "    \"n_arrested\",\n",
    "    \"n_unharmed\",\n",
    "    \"n_participants\",\n",
    "]\n",
    "\n",
    "age_vars = [\n",
    "    \"participant_age1\",\n",
    "    \"min_age_participants\",\n",
    "    \"avg_age_participants\",\n",
    "    \"max_age_participants\",\n",
    "]\n",
    "\n",
    "for var in non_negative_vars:\n",
    "    print(var)\n",
    "    tmp = incidents_df.loc[incidents_df[var].notna()]\n",
    "    if var in age_vars:\n",
    "        print(\n",
    "            tmp.loc[tmp[var] < 0].shape[0] / incidents_df.shape[0] * 100\n",
    "            + tmp.loc[tmp[var] > 116].shape[0] / incidents_df.shape[0] * 100\n",
    "        )\n",
    "        incidents_df.loc[incidents_df[var] < 0, var] = np.NaN\n",
    "        incidents_df.loc[incidents_df[var] > 116, var] = np.NaN\n",
    "    else:\n",
    "        print(tmp.loc[tmp[var] < 0].shape[0] / incidents_df.shape[0] * 100)\n",
    "        incidents_df.loc[incidents_df[var] < 0, var] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other variables that should be constrained in a specific range are coordinates. Now, to be precise we should check that all coordinates match the respsective county or city, but here we just investigate cases where coordinates are not in the USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(incidents_df[\"latitude\"]))\n",
    "print(np.max(incidents_df[\"latitude\"]))\n",
    "print(np.min(incidents_df[\"longitude\"]))\n",
    "print(np.max(incidents_df[\"longitude\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.loc[incidents_df[\"longitude\"] > -60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.loc[incidents_df[\"longitude\"] > -60, \"longitude\"] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, there are only 5 cases where the longitude attribute seems wrong. So we can try to check if changing the sign of the longitude is consistent with the rest of the information on the location.\n",
    "\n",
    "Using google maps, we verify that all the 5 locations match if the lognitude's sign is reverse. Moreover, these 5 incidents are all TSA Actions in different airports.\n",
    "\n",
    "We can now correct the coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.loc[incidents_df[\"longitude\"] > -60, \"longitude\"] = -incidents_df.loc[\n",
    "    incidents_df[\"longitude\"] > -60, \"longitude\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_notna = incidents_df.loc[incidents_df[\"min_age_participants\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"max_age_participants\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"avg_age_participants\"].notna()]\n",
    "\n",
    "tmp = tmp_notna.loc[\n",
    "    tmp_notna[\"max_age_participants\"] >= tmp_notna[\"avg_age_participants\"]\n",
    "]\n",
    "tmp = tmp.loc[tmp[\"min_age_participants\"] <= tmp[\"avg_age_participants\"]]\n",
    "\n",
    "tmp.shape[0] / tmp_notna.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_notna = incidents_df.loc[incidents_df[\"min_age_participants\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"max_age_participants\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"participant_age1\"].notna()]\n",
    "\n",
    "tmp = tmp_notna.loc[tmp_notna[\"max_age_participants\"] >= tmp_notna[\"participant_age1\"]]\n",
    "tmp = tmp.loc[tmp[\"min_age_participants\"] <= tmp[\"participant_age1\"]]\n",
    "\n",
    "tmp.shape[0] / tmp_notna.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check that the number of a special categrory of participants if not larger than the total number of participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\n",
    "    \"n_killed\",\n",
    "    \"n_injured\",\n",
    "    \"n_unharmed\",\n",
    "    \"n_arrested\",\n",
    "    \"n_participants_child\",\n",
    "    \"n_participants_teen\",\n",
    "    \"n_participants_adult\",\n",
    "    \"n_males\",\n",
    "    \"n_females\",\n",
    "]:\n",
    "    print(col)\n",
    "    tmp_notna = incidents_df.loc[incidents_df[col].notna()]\n",
    "    tmp = tmp_notna.loc[tmp_notna[col] > tmp_notna[\"n_participants\"]]\n",
    "\n",
    "    print(tmp.shape[0] / tmp_notna.shape[0] * 100)\n",
    "\n",
    "    incidents_df[col][tmp.index] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing that we may want to check is the information about the number of participants.\n",
    "We expect the fllowing equalities to hold:\n",
    "* n_participants = n_males + n_females \n",
    "* n_participants = n_participants_child + n_participants_teen + n_participants_adult\n",
    "* n_participants = n_killed + n_unharmed + n_injured \n",
    "or\n",
    "* n_participants = n_killed + n_unharmed + n_injured + n_arrested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_notna = incidents_df.loc[incidents_df[\"n_killed\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_injured\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_unharmed\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_arrested\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_participants\"].notna()]\n",
    "\n",
    "tmp = tmp_notna.loc[\n",
    "    tmp_notna[\"n_killed\"]\n",
    "    + tmp_notna[\"n_injured\"]\n",
    "    + tmp_notna[\"n_unharmed\"]\n",
    "    + tmp_notna[\"n_arrested\"]\n",
    "    == tmp_notna[\"n_participants\"]\n",
    "]\n",
    "\n",
    "tmp.shape[0] / tmp_notna.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_notna = incidents_df.loc[incidents_df[\"n_killed\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_injured\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_unharmed\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_arrested\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_participants\"].notna()]\n",
    "\n",
    "tmp_notna = tmp_notna.loc[\n",
    "    tmp_notna[\"n_killed\"]\n",
    "    + tmp_notna[\"n_injured\"]\n",
    "    + tmp_notna[\"n_unharmed\"]\n",
    "    + tmp_notna[\"n_arrested\"]\n",
    "    != tmp_notna[\"n_participants\"]\n",
    "]\n",
    "\n",
    "tmp = tmp_notna.loc[\n",
    "    tmp_notna[\"n_killed\"] + tmp_notna[\"n_injured\"] + tmp_notna[\"n_unharmed\"]\n",
    "    == tmp_notna[\"n_participants\"]\n",
    "]\n",
    "\n",
    "tmp.shape[0] / tmp_notna.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>city_or_county</th>\n",
       "      <th>address</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>congressional_district</th>\n",
       "      <th>state_house_district</th>\n",
       "      <th>state_senate_district</th>\n",
       "      <th>...</th>\n",
       "      <th>n_males</th>\n",
       "      <th>n_females</th>\n",
       "      <th>n_killed</th>\n",
       "      <th>n_injured</th>\n",
       "      <th>n_arrested</th>\n",
       "      <th>n_unharmed</th>\n",
       "      <th>n_participants</th>\n",
       "      <th>notes</th>\n",
       "      <th>incident_characteristics1</th>\n",
       "      <th>incident_characteristics2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-15</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>Washington</td>\n",
       "      <td>1000 block of Bladensburg Road, NE</td>\n",
       "      <td>38.9030</td>\n",
       "      <td>-76.9820</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2029-11-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Rockford</td>\n",
       "      <td>East State and Bell School Road</td>\n",
       "      <td>42.2704</td>\n",
       "      <td>-88.9703</td>\n",
       "      <td>16.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hoffman House and Scoreboard sports bar - Robb...</td>\n",
       "      <td>Defensive Use</td>\n",
       "      <td>Institution/Group/Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Little Rock</td>\n",
       "      <td>3100 block of Boyle Park Road</td>\n",
       "      <td>34.7219</td>\n",
       "      <td>-92.3574</td>\n",
       "      <td>2.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shots Fired - No Injuries</td>\n",
       "      <td>Armed robbery with injury/death and/or evidenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2029-07-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California</td>\n",
       "      <td>San Dimas</td>\n",
       "      <td>865 W. Arrow Highway</td>\n",
       "      <td>34.1067</td>\n",
       "      <td>-117.8240</td>\n",
       "      <td>32.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>at Check Into Cash</td>\n",
       "      <td>Armed robbery with injury/death and/or evidenc...</td>\n",
       "      <td>Institution/Group/Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2014-05-02</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>Murrells Inlet</td>\n",
       "      <td>5190 Highway 17 Bypass</td>\n",
       "      <td>33.5353</td>\n",
       "      <td>-79.0543</td>\n",
       "      <td>7.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Not 2 Shabby</td>\n",
       "      <td>Armed robbery with injury/death and/or evidenc...</td>\n",
       "      <td>Institution/Group/Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239158</th>\n",
       "      <td>2015-08-04</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>1400 block of Hamilton Avenue</td>\n",
       "      <td>39.7860</td>\n",
       "      <td>-86.1258</td>\n",
       "      <td>7.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2 men stable after drug robbery/attack; 1 shoo...</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>Drug involvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239242</th>\n",
       "      <td>2014-09-07</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>416 S. Ninth St.</td>\n",
       "      <td>39.8217</td>\n",
       "      <td>-84.8904</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Family Dollar - robbed at gunpoint; suspect ap...</td>\n",
       "      <td>Drug involvement</td>\n",
       "      <td>Armed robbery with injury/death and/or evidenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239246</th>\n",
       "      <td>2016-09-16</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Bakersfield</td>\n",
       "      <td>2340 Niles Street</td>\n",
       "      <td>35.3760</td>\n",
       "      <td>-118.9650</td>\n",
       "      <td>23.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>attempt to rob marijuana dispensary, shots exc...</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>Institution/Group/Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239266</th>\n",
       "      <td>2016-06-20</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Columbus</td>\n",
       "      <td>4700 block of Lemarie Place</td>\n",
       "      <td>39.9612</td>\n",
       "      <td>-82.9988</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1 wounded, head, when 2 men fired on him in pa...</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239280</th>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Fort Worth</td>\n",
       "      <td>5300 block of Conroy</td>\n",
       "      <td>32.6679</td>\n",
       "      <td>-97.3114</td>\n",
       "      <td>33.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1 killed. Perps are people detained at hospita...</td>\n",
       "      <td>Shot - Wounded/Injured</td>\n",
       "      <td>Shot - Dead (murder, accidental, suicide)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10553 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date    year                 state  city_or_county  \\\n",
       "3       2016-10-15  2016.0  District of Columbia      Washington   \n",
       "35      2029-11-02     NaN              Illinois        Rockford   \n",
       "37      2017-05-25  2017.0              Arkansas     Little Rock   \n",
       "140     2029-07-03     NaN            California       San Dimas   \n",
       "174     2014-05-02  2014.0        South Carolina  Murrells Inlet   \n",
       "...            ...     ...                   ...             ...   \n",
       "239158  2015-08-04  2015.0               Indiana    Indianapolis   \n",
       "239242  2014-09-07  2014.0               Indiana        Richmond   \n",
       "239246  2016-09-16  2016.0            California     Bakersfield   \n",
       "239266  2016-06-20  2016.0                  Ohio        Columbus   \n",
       "239280  2016-06-15  2016.0                 Texas      Fort Worth   \n",
       "\n",
       "                                   address  latitude  longitude  \\\n",
       "3       1000 block of Bladensburg Road, NE   38.9030   -76.9820   \n",
       "35         East State and Bell School Road   42.2704   -88.9703   \n",
       "37           3100 block of Boyle Park Road   34.7219   -92.3574   \n",
       "140                  865 W. Arrow Highway    34.1067  -117.8240   \n",
       "174                5190 Highway 17 Bypass    33.5353   -79.0543   \n",
       "...                                    ...       ...        ...   \n",
       "239158       1400 block of Hamilton Avenue   39.7860   -86.1258   \n",
       "239242                    416 S. Ninth St.   39.8217   -84.8904   \n",
       "239246                   2340 Niles Street   35.3760  -118.9650   \n",
       "239266         4700 block of Lemarie Place   39.9612   -82.9988   \n",
       "239280                5300 block of Conroy   32.6679   -97.3114   \n",
       "\n",
       "        congressional_district  state_house_district  state_senate_district  \\\n",
       "3                          1.0                   NaN                    NaN   \n",
       "35                        16.0                  68.0                   34.0   \n",
       "37                         2.0                  34.0                   31.0   \n",
       "140                       32.0                  41.0                   25.0   \n",
       "174                        7.0                 108.0                   34.0   \n",
       "...                        ...                   ...                    ...   \n",
       "239158                     7.0                  96.0                   34.0   \n",
       "239242                     6.0                  56.0                   27.0   \n",
       "239246                    23.0                  32.0                   16.0   \n",
       "239266                     3.0                  18.0                   15.0   \n",
       "239280                    33.0                  95.0                   10.0   \n",
       "\n",
       "        ...  n_males n_females n_killed n_injured n_arrested n_unharmed  \\\n",
       "3       ...      1.0       0.0      0.0       1.0        0.0        0.0   \n",
       "35      ...      1.0       0.0      0.0       0.0        0.0        1.0   \n",
       "37      ...      1.0       0.0      0.0       0.0        0.0        1.0   \n",
       "140     ...      1.0       0.0      0.0       0.0        0.0        1.0   \n",
       "174     ...      2.0       0.0      0.0       0.0        0.0        2.0   \n",
       "...     ...      ...       ...      ...       ...        ...        ...   \n",
       "239158  ...      5.0       0.0      0.0       3.0        3.0        0.0   \n",
       "239242  ...      1.0       0.0      0.0       0.0        0.0        1.0   \n",
       "239246  ...      1.0       0.0      0.0       1.0        0.0        0.0   \n",
       "239266  ...      1.0       0.0      0.0       1.0        0.0        0.0   \n",
       "239280  ...      1.0       0.0      1.0       1.0        2.0        0.0   \n",
       "\n",
       "       n_participants                                              notes  \\\n",
       "3                 2.0                                                NaN   \n",
       "35                2.0  Hoffman House and Scoreboard sports bar - Robb...   \n",
       "37                4.0                                                NaN   \n",
       "140               2.0                                at Check Into Cash    \n",
       "174               3.0                                       Not 2 Shabby   \n",
       "...               ...                                                ...   \n",
       "239158            5.0  2 men stable after drug robbery/attack; 1 shoo...   \n",
       "239242            2.0  Family Dollar - robbed at gunpoint; suspect ap...   \n",
       "239246            2.0  attempt to rob marijuana dispensary, shots exc...   \n",
       "239266            3.0  1 wounded, head, when 2 men fired on him in pa...   \n",
       "239280            3.0  1 killed. Perps are people detained at hospita...   \n",
       "\n",
       "                                incident_characteristics1  \\\n",
       "3                                  Shot - Wounded/Injured   \n",
       "35                                          Defensive Use   \n",
       "37                              Shots Fired - No Injuries   \n",
       "140     Armed robbery with injury/death and/or evidenc...   \n",
       "174     Armed robbery with injury/death and/or evidenc...   \n",
       "...                                                   ...   \n",
       "239158                             Shot - Wounded/Injured   \n",
       "239242                                   Drug involvement   \n",
       "239246                             Shot - Wounded/Injured   \n",
       "239266                             Shot - Wounded/Injured   \n",
       "239280                             Shot - Wounded/Injured   \n",
       "\n",
       "                                incident_characteristics2  \n",
       "3                                                     NaN  \n",
       "35                             Institution/Group/Business  \n",
       "37      Armed robbery with injury/death and/or evidenc...  \n",
       "140                            Institution/Group/Business  \n",
       "174                            Institution/Group/Business  \n",
       "...                                                   ...  \n",
       "239158                                   Drug involvement  \n",
       "239242  Armed robbery with injury/death and/or evidenc...  \n",
       "239246                         Institution/Group/Business  \n",
       "239266                                                NaN  \n",
       "239280          Shot - Dead (murder, accidental, suicide)  \n",
       "\n",
       "[10553 rows x 29 columns]"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_notna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp_notna.loc[\n",
    "    tmp_notna[\"n_killed\"]\n",
    "    + tmp_notna[\"n_injured\"]\n",
    "    + tmp_notna[\"n_unharmed\"]\n",
    "    + tmp_notna[\"n_arrested\"]\n",
    "    != tmp_notna[\"n_participants\"]\n",
    "]\n",
    "for i in tmp.index:\n",
    "    tot = (\n",
    "        incidents_df[\"n_killed\"][i]\n",
    "        + incidents_df[\"n_injured\"][i]\n",
    "        + incidents_df[\"n_arrested\"][i]\n",
    "        + incidents_df[\"n_unharmed\"][i]\n",
    "    )\n",
    "    if tot > 0:\n",
    "        for var in [\"n_killed\", \"n_injured\", \"n_arrested\"]:\n",
    "            incidents_df[var][i] = int(\n",
    "                (incidents_df[var][i] / tot) * incidents_df[\"n_participants\"][i]\n",
    "            )\n",
    "        incidents_df[\"n_unharmed\"][i] = (\n",
    "            incidents_df[\"n_participants\"][i]\n",
    "            - incidents_df[\"n_killed\"][i]\n",
    "            - incidents_df[\"n_injured\"][i]\n",
    "            - incidents_df[\"n_arrested\"][i]\n",
    "        )\n",
    "    else:\n",
    "        incidents_df[\"n_killed\"][i] = np.NaN\n",
    "        incidents_df[\"n_injured\"][i] = np.NaN\n",
    "        incidents_df[\"n_arrested\"][i] = np.NaN\n",
    "        incidents_df[\"n_unharmed\"][i] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_notna = incidents_df.loc[incidents_df[\"n_participants_child\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_participants_teen\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_participants_adult\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_participants\"].notna()]\n",
    "\n",
    "tmp = tmp_notna.loc[\n",
    "    tmp_notna[\"n_participants_child\"]\n",
    "    + tmp_notna[\"n_participants_teen\"]\n",
    "    + tmp_notna[\"n_participants_adult\"]\n",
    "    == tmp_notna[\"n_participants\"]\n",
    "]\n",
    "\n",
    "tmp.shape[0] / tmp_notna.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp_notna.loc[\n",
    "    tmp_notna[\"n_participants_child\"]\n",
    "    + tmp_notna[\"n_participants_teen\"]\n",
    "    + tmp_notna[\"n_participants_adult\"]\n",
    "    != tmp_notna[\"n_participants\"]\n",
    "]\n",
    "for i in tmp.index:\n",
    "    tot = (\n",
    "        incidents_df[\"n_participants_child\"][i]\n",
    "        + incidents_df[\"n_participants_teen\"][i]\n",
    "        + incidents_df[\"n_participants_adult\"][i]\n",
    "    )\n",
    "    if tot > 0:\n",
    "        for var in [\"n_participants_child\", \"n_participants_teen\"]:\n",
    "            incidents_df[var][i] = int(\n",
    "                (incidents_df[var][i] / tot) * incidents_df[\"n_participants\"][i]\n",
    "            )\n",
    "        incidents_df[\"n_participants_adult\"][i] = (\n",
    "            incidents_df[\"n_participants\"][i]\n",
    "            - incidents_df[\"n_participants_child\"][i]\n",
    "            - incidents_df[\"n_participants_teen\"][i]\n",
    "        )\n",
    "    else:\n",
    "        tmp_notna[\"n_participants_child\"][i] = np.NaN\n",
    "        tmp_notna[\"n_participants_teen\"][i] = np.NaN\n",
    "        tmp_notna[\"n_participants_adult\"][i] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_notna = incidents_df.loc[incidents_df[\"n_males\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_females\"].notna()]\n",
    "tmp_notna = tmp_notna.loc[tmp_notna[\"n_participants\"].notna()]\n",
    "\n",
    "tmp = tmp_notna.loc[\n",
    "    tmp_notna[\"n_males\"] + tmp_notna[\"n_females\"] == tmp_notna[\"n_participants\"]\n",
    "]\n",
    "\n",
    "tmp.shape[0] / tmp_notna.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp_notna.loc[\n",
    "    tmp_notna[\"n_males\"] + tmp_notna[\"n_females\"] != tmp_notna[\"n_participants\"]\n",
    "]\n",
    "\n",
    "for i in tmp.index:\n",
    "    tot = incidents_df[\"n_males\"][i] + incidents_df[\"n_females\"][i]\n",
    "    if tot > 0:\n",
    "        incidents_df[\"n_males\"][i] = int(\n",
    "            (incidents_df[\"n_males\"][i] / tot) * incidents_df[\"n_participants\"][i]\n",
    "        )\n",
    "        incidents_df[\"n_females\"][i] = (\n",
    "            incidents_df[\"n_participants\"][i] - incidents_df[\"n_males\"][i]\n",
    "        )\n",
    "    else:\n",
    "        incidents_df[\"n_males\"][i] = np.NaN\n",
    "        incidents_df[\"n_females\"][i] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if the count is not always correct, for now we keep the information about the group composition as it could still be useful. Also because it would be difficult to identify the incorrect value among the different attributes in the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.loc[incidents_df[\"n_participants\"] == 0].shape[0] / incidents_df.shape[\n",
    "    0\n",
    "] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in [\n",
    "    \"n_males\",\n",
    "    \"n_females\",\n",
    "    \"n_killed\",\n",
    "    \"n_injured\",\n",
    "    \"n_unharmed\",\n",
    "    \"n_arrested\",\n",
    "    \"n_participants_adult\",\n",
    "    \"n_participants_teen\",\n",
    "    \"n_participants_child\",\n",
    "]:\n",
    "    print(\n",
    "        incidents_df.loc[\n",
    "            (incidents_df[\"n_participants\"] == 0) & (incidents_df[var] > 0)\n",
    "        ].shape[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_df.loc[incidents_df[\"n_participants\"] == 0, \"n_participants\"] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(incidents_df.isnull().sum() / incidents_df.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = incidents_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"povertyPercentage\"] = \" \"\n",
    "joined_df[\"party\"] = \" \"\n",
    "joined_df[\"candidatevotes\"] = \" \"\n",
    "joined_df[\"totalvotes\"] = \" \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid dates: 1/1/2013 to 31/3/2018. \\\n",
    "there are a lot of incidents with wrong dates (2028-2030). \\\n",
    "Ho googlato un po' di notizie usando le note del dataset, le città ecc. e sembra che 2028->2013; 2029->2014; 2030->2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "for i in range(joined_df.shape[0]):\n",
    "    if int(joined_df[\"date\"][i][0:4]) > 2018:\n",
    "        joined_df[\"year\"][i] = int(joined_df[\"date\"][i][0:4]) - 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(joined_df.shape[0]):\n",
    "    povertyPercentage = poverty_df.loc[\n",
    "        (poverty_df[\"year\"] == joined_df.loc[i, \"year\"])\n",
    "        & (poverty_df[\"state\"] == joined_df.loc[i, \"state\"]),\n",
    "        \"povertyPercentage\",\n",
    "    ].values\n",
    "\n",
    "    if len(povertyPercentage) == 1:\n",
    "        joined_df[\"povertyPercentage\"][i] = povertyPercentage[0]\n",
    "    else:\n",
    "        joined_df[\"povertyPercentage\"][i] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congressional elections occur every 2 years!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(joined_df.shape[0]):\n",
    "    party = district_house_df.loc[\n",
    "        (district_house_df[\"year\"] // 2 == joined_df[\"year\"][i] // 2)\n",
    "        & (district_house_df[\"state\"] == joined_df[\"state\"][i].upper())\n",
    "        & (\n",
    "            district_house_df[\"congressional_district\"]\n",
    "            == joined_df[\"congressional_district\"][i]\n",
    "        ),\n",
    "        \"party\",\n",
    "    ].values\n",
    "\n",
    "    if len(party) == 1:\n",
    "        joined_df[\"party\"][i] = party[0]\n",
    "    else:\n",
    "        joined_df[\"party\"][i] = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(joined_df.shape[0]):\n",
    "    candidatevotes = district_house_df.loc[\n",
    "        (district_house_df[\"year\"] // 2 == joined_df.loc[i, \"year\"] // 2)\n",
    "        & (district_house_df[\"state\"] == joined_df.loc[i, \"state\"].upper())\n",
    "        & (\n",
    "            district_house_df[\"congressional_district\"]\n",
    "            == joined_df.loc[i, \"congressional_district\"]\n",
    "        ),\n",
    "        \"candidatevotes\",\n",
    "    ].values\n",
    "\n",
    "    if len(candidatevotes) == 1:\n",
    "        joined_df[\"candidatevotes\"][i] = candidatevotes[0]\n",
    "    else:\n",
    "        joined_df[\"candidatevotes\"][i] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(joined_df.shape[0]):\n",
    "    totalvotes = district_house_df.loc[\n",
    "        (district_house_df[\"year\"] // 2 == joined_df.loc[i, \"year\"] // 2)\n",
    "        & (district_house_df[\"state\"] == joined_df.loc[i, \"state\"].upper())\n",
    "        & (\n",
    "            district_house_df[\"congressional_district\"]\n",
    "            == joined_df.loc[i, \"congressional_district\"]\n",
    "        ),\n",
    "        \"totalvotes\",\n",
    "    ].values\n",
    "\n",
    "    if len(totalvotes) == 1:\n",
    "        joined_df[\"totalvotes\"][i] = totalvotes[0]\n",
    "    else:\n",
    "        joined_df[\"totalvotes\"][i] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.to_csv(\"data/joined_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = pd.read_csv(\"data/joined_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_randomly_within_group(df, value_column, group_columns=[]):\n",
    "    if len(group_columns) > 0:\n",
    "        grouped = df.groupby(group_columns)\n",
    "        for _, group_df in grouped:\n",
    "            non_missing_values = group_df[value_column].dropna()\n",
    "            missing_indices = group_df.index[\n",
    "                group_df[value_column].isnull().any(axis=1)\n",
    "            ]\n",
    "            if non_missing_values.shape[0] > 0:\n",
    "                random_indexes = np.random.choice(\n",
    "                    [i for i in non_missing_values.index],\n",
    "                    size=len(missing_indices),\n",
    "                )\n",
    "                for var in value_column:\n",
    "                    df.loc[missing_indices, var] = df.loc[random_indexes, var].values\n",
    "    else:\n",
    "        non_missing_values = df[value_column].dropna()\n",
    "        missing_indices = df.index[df[value_column].isnull().any(axis=1)]\n",
    "        if non_missing_values.shape[0] > 0:\n",
    "            random_indexes = np.random.choice(\n",
    "                [i for i in non_missing_values.index],\n",
    "                size=len(missing_indices),\n",
    "            )\n",
    "            for var in value_column:\n",
    "                df.loc[missing_indices, var] = df.loc[random_indexes, var].values\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = fill_missing_randomly_within_group(\n",
    "    joined_df, [\"latitude\", \"longitude\"], [\"state\", \"city_or_county\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have no info about city, we use states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = fill_missing_randomly_within_group(\n",
    "    joined_df, [\"latitude\", \"longitude\"], [\"state\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = fill_missing_randomly_within_group(\n",
    "    joined_df,\n",
    "    [\"min_age_participants\", \"avg_age_participants\", \"max_age_participants\"],\n",
    "    [\"state\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = fill_missing_randomly_within_group(\n",
    "    joined_df, [\"n_participants\"], [\"state\", \"year\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "males/females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"n_males\"] = joined_df[\"n_males\"].div(\n",
    "    (joined_df[\"n_participants\"]).replace(0, 1)\n",
    ")\n",
    "\n",
    "joined_df = fill_missing_randomly_within_group(joined_df, [\"n_males\"], [\"state\"])\n",
    "\n",
    "joined_df[\"n_males\"] = (joined_df[\"n_males\"] * joined_df[\"n_participants\"]).astype(int)\n",
    "joined_df[\"n_females\"] = (joined_df[\"n_participants\"] - joined_df[\"n_males\"]).astype(\n",
    "    int\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adults/teen/children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"n_participants_adult\"] = joined_df[\"n_participants_adult\"].div(\n",
    "    (joined_df[\"n_participants\"]).replace(0, 1)\n",
    ")\n",
    "joined_df[\"n_participants_teen\"] = joined_df[\"n_participants_teen\"].div(\n",
    "    (joined_df[\"n_participants\"]).replace(0, 1)\n",
    ")\n",
    "\n",
    "joined_df = fill_missing_randomly_within_group(\n",
    "    joined_df, [\"n_participants_adult\", \"n_participants_teen\"], [\"state\"]\n",
    ")\n",
    "\n",
    "joined_df[\"n_participants_adult\"] = (\n",
    "    joined_df[\"n_participants_adult\"] * joined_df[\"n_participants\"]\n",
    ").astype(int)\n",
    "joined_df[\"n_participants_teen\"] = (\n",
    "    joined_df[\"n_participants_teen\"] * joined_df[\"n_participants\"]\n",
    ").astype(int)\n",
    "joined_df[\"n_participants_child\"] = (\n",
    "    joined_df[\"n_participants\"]\n",
    "    - joined_df[\"n_participants_adult\"]\n",
    "    - joined_df[\"n_participants_teen\"]\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "killed/injured/arrested/unharmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"n_killed\"] = joined_df[\"n_killed\"].div(\n",
    "    (joined_df[\"n_participants\"]).replace(0, 1)\n",
    ")\n",
    "joined_df[\"n_injured\"] = joined_df[\"n_injured\"].div(\n",
    "    (joined_df[\"n_participants\"]).replace(0, 1)\n",
    ")\n",
    "joined_df[\"n_arrested\"] = joined_df[\"n_arrested\"].div(\n",
    "    (joined_df[\"n_participants\"]).replace(0, 1)\n",
    ")\n",
    "\n",
    "joined_df = fill_missing_randomly_within_group(\n",
    "    joined_df, [\"n_killed\", \"n_injured\", \"n_arrested\", \"n_unharmed\"], [\"state\"]\n",
    ")\n",
    "\n",
    "joined_df[\"n_killed\"] = (joined_df[\"n_killed\"] * joined_df[\"n_participants\"]).astype(\n",
    "    int\n",
    ")\n",
    "joined_df[\"n_injured\"] = (joined_df[\"n_injured\"] * joined_df[\"n_participants\"]).astype(\n",
    "    int\n",
    ")\n",
    "joined_df[\"n_arrested\"] = (\n",
    "    joined_df[\"n_arrested\"] * joined_df[\"n_participants\"]\n",
    ").astype(int)\n",
    "\n",
    "joined_df[\"n_unharmed\"] = (\n",
    "    joined_df[\"n_unharmed\"] * joined_df[\"n_participants\"]\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Party and votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.loc[joined_df[\"party\"] == \" \", \"party\"] = np.NaN\n",
    "joined_df.loc[joined_df[\"totalvotes\"] == 0, \"totalvotes\"] = np.NaN\n",
    "joined_df.loc[joined_df[\"candidatevotes\"] == 0, \"candidatevotes\"] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = fill_missing_randomly_within_group(\n",
    "    joined_df,\n",
    "    [\"party\", \"totalvotes\", \"candidatevotes\"],\n",
    "    [\"state\", \"congressional_district\"],\n",
    ")\n",
    "joined_df = fill_missing_randomly_within_group(\n",
    "    joined_df,\n",
    "    [\"party\", \"totalvotes\", \"candidatevotes\"],\n",
    "    [\"state\", \"city_or_county\", \"year\"],\n",
    ")\n",
    "joined_df = fill_missing_randomly_within_group(\n",
    "    joined_df, [\"party\", \"totalvotes\", \"candidatevotes\"], [\"state\", \"year\"]\n",
    ")\n",
    "\n",
    "joined_df = fill_missing_randomly_within_group(\n",
    "    joined_df, [\"party\", \"totalvotes\", \"candidatevotes\"], [\"year\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined_df[joined_df[\"party\"].isna()].shape[0] / joined_df.shape[0])\n",
    "print(joined_df[joined_df[\"totalvotes\"].isna()].shape[0] / joined_df.shape[0])\n",
    "print(joined_df[joined_df[\"candidatevotes\"].isna()].shape[0] / joined_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove / modify attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = joined_df.drop(\n",
    "    columns=[\n",
    "        \"address\",\n",
    "        \"congressional_district\",\n",
    "        \"state_house_district\",\n",
    "        \"state_senate_district\",\n",
    "        \"participant_age1\",\n",
    "        \"participant_age_group1\",\n",
    "        \"participant_gender1\",\n",
    "        \"notes\",\n",
    "        \"incident_characteristics1\",\n",
    "        \"incident_characteristics2\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.insert(\n",
    "    1,\n",
    "    \"month\",\n",
    "    [int(joined_df[\"date\"][i][5:7]) for i in range(joined_df.shape[0])],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_per_month = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "\n",
    "def compute_progressive_date(date):\n",
    "    \"\"\"Compute the progressive date of the incident, starting from 01/01/2013.\n",
    "    Data in \"date\" column are in the format \"YYYY-MM-DD\".\n",
    "\n",
    "    Args:\n",
    "        x (str): date of the incident\n",
    "\n",
    "    Returns:\n",
    "        int: progressive date of the incident\n",
    "    \"\"\"\n",
    "    return (int(date[0:4])) * 365 + days_per_month[int(date[5:7]) - 1] + int(date[8:10])\n",
    "\n",
    "for i in range(joined_df.shape[0]):\n",
    "    joined_df[\"date\"][i] = compute_progressive_date(joined_df[\"date\"][i])\n",
    "\n",
    "    # Incidents are between 2013 and 2017, the only bisestile 2016:\n",
    "    if (joined_df[\"year\"][i] == 2016 and joined_df[\"month\"][i] >= 3) or joined_df[\"year\"][i] > 2016:\n",
    "        joined_df[\"date\"][i] = joined_df[\"date\"][i] + 1\n",
    "\n",
    "start_date = joined_df[\"date\"].min()\n",
    "joined_df[\"date\"] = joined_df[\"date\"] - start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.loc[joined_df[\"party\"] == \"DEMOCRATIC-FARMER-LABOR\", \"party\"] = \"DEMOCRAT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"republicans_ratio\"] = \" \"\n",
    "joined_df[\"democrats_ratio\"] = \" \"\n",
    "\n",
    "for i in joined_df.index:\n",
    "    if joined_df[\"party\"][i] == \"REPUBLICAN\":\n",
    "        joined_df[\"republicans_ratio\"][i] = (\n",
    "            joined_df[\"candidatevotes\"][i] / joined_df[\"totalvotes\"][i]\n",
    "        )\n",
    "        joined_df[\"democrats_ratio\"][i] = 1 - joined_df[\"republicans_ratio\"][i]\n",
    "    else:\n",
    "        joined_df[\"democrats_ratio\"][i] = (\n",
    "            joined_df[\"candidatevotes\"][i] / joined_df[\"totalvotes\"][i]\n",
    "        )\n",
    "        joined_df[\"republicans_ratio\"][i] = 1 - joined_df[\"democrats_ratio\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.drop([\"candidatevotes\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.isna().sum() / joined_df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\n",
    "    [\n",
    "        \"min_age_participants\",\n",
    "        \"max_age_participants\",\n",
    "        \"n_participants_child\",\n",
    "        \"n_participants_teen\",\n",
    "        \"n_participants_adult\",\n",
    "        \"povertyPercentage\",\n",
    "    ]\n",
    "] = joined_df[\n",
    "    [\n",
    "        \"min_age_participants\",\n",
    "        \"max_age_participants\",\n",
    "        \"n_participants_child\",\n",
    "        \"n_participants_teen\",\n",
    "        \"n_participants_adult\",\n",
    "        \"povertyPercentage\",\n",
    "    ]\n",
    "].astype(\n",
    "    float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_normalize = [\n",
    "    \"n_arrested\",\n",
    "    \"n_unharmed\",\n",
    "    \"n_killed\",\n",
    "    \"n_injured\",\n",
    "    \"n_participants_adult\",\n",
    "    \"n_participants_teen\",\n",
    "    \"n_participants_child\",\n",
    "    \"n_males\",\n",
    "    \"n_females\",\n",
    "]\n",
    "\n",
    "# Normalize columns by dividing each element by n_participants\n",
    "joined_df[columns_to_normalize] = joined_df[columns_to_normalize].div(\n",
    "    joined_df[\"n_participants\"], axis=0\n",
    ")\n",
    "\n",
    "joined_df = joined_df.rename(\n",
    "    columns={\n",
    "        \"n_arrested\": \"arrested_ratio\",\n",
    "        \"n_unharmed\": \"unharmed_ratio\",\n",
    "        \"n_killed\": \"killed_ratio\",\n",
    "        \"n_injured\": \"injured_ratio\",\n",
    "        \"n_participants_adult\": \"adults_ratio\",\n",
    "        \"n_participants_teen\": \"teen_ratio\",\n",
    "        \"n_participants_child\": \"children_ratio\",\n",
    "        \"n_males\": \"males_ratio\",\n",
    "        \"n_females\": \"females_ratio\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_df = pd.read_csv(\"data/population.csv\")\n",
    "population_df = population_df[[\"placeName\", \"Date:Count_Person\", \"Value:Count_Person\"]]\n",
    "population_df = population_df.astype({})\n",
    "population_df = population_df.rename(\n",
    "    columns={\n",
    "        \"placeName\": \"state\",\n",
    "        \"Date:Count_Person\": \"year\",\n",
    "        \"Value:Count_Person\": \"population\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"state_population\"] = \" \"\n",
    "\n",
    "for i in range(joined_df.shape[0]):\n",
    "    year_condition = population_df[\"year\"] == joined_df[\"year\"][i]\n",
    "    state_condition = population_df[\"state\"] == joined_df[\"state\"][i]\n",
    "    population = population_df.loc[\n",
    "        year_condition & state_condition, \"population\"\n",
    "    ].values\n",
    "\n",
    "    if len(population) == 1:\n",
    "        joined_df[\"state_population\"][i] = population[0]\n",
    "    else:\n",
    "        joined_df[\"state_population\"][i] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce a new column in dataframe for indicating whether a city is populous or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_pop_cities = [\n",
    "    \"New York\",\n",
    "    \"Los Angeles\",\n",
    "    \"Chicago\",\n",
    "    \"Houston\",\n",
    "    \"Phoenix\",\n",
    "    \"Philadelphia\",\n",
    "    \"San Antonio\",\n",
    "    \"San Diego\",\n",
    "    \"Dallas\",\n",
    "    \"San Jose\",\n",
    "    \"Austin\",\n",
    "    \"Jacksonville\",\n",
    "    \"San Francisco\",\n",
    "    \"Columbus\",\n",
    "    \"Fort Worth\",\n",
    "    \"Indianapolis\",\n",
    "    \"Charlotte\",\n",
    "    \"Seattle\",\n",
    "    \"Denver\",\n",
    "    \"Washington\",\n",
    "    \"Boston\",\n",
    "    \"El Paso\",\n",
    "    \"Detroit\",\n",
    "    \"Nashville\",\n",
    "    \"Memphis\",\n",
    "    \"Portland\",\n",
    "    \"Oklahoma City\",\n",
    "    \"Las Vegas\",\n",
    "    \"Louisville\",\n",
    "    \"Baltimore\",\n",
    "    \"Milwaukee\",\n",
    "    \"Albuquerque\",\n",
    "    \"Tucson\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[\"populous_city\"] = \" \"    \n",
    "\n",
    "count = 0\n",
    "for i in joined_df.index:\n",
    "    if joined_df[\"populous_city\"][i] in very_pop_cities:\n",
    "        joined_df[\"populous_city\"][i] = 1\n",
    "        count = count + 1\n",
    "    else:\n",
    "        joined_df[\"populous_city\"][i] = 0\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Variables distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "colors = {\n",
    "    \"DEMOCRAT\": \"blue\",\n",
    "    \"DEMOCRATIC-FARMER-LABOR\": \"purple\",\n",
    "    \"REPUBLICAN\": \"red\",\n",
    "    \" \": \"gray\",\n",
    "}\n",
    "usa = plt.imread(\"images/NorthAmerica.png\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 9))\n",
    "for i, y in enumerate([2012, 2014, 2016, 2018]):\n",
    "    axs[i // 2, i % 2].imshow(usa, extent=[-180, -60, 20, 80])\n",
    "    year_df = joined_df.loc[joined_df[\"year\"] // 2 == y // 2]\n",
    "    if y == 2012:\n",
    "        axs[i // 2, i % 2].set_title(f\"2013\", fontsize=20)\n",
    "    elif y == 2018:\n",
    "        axs[i // 2, i % 2].set_title(f\"2018\", fontsize=20)\n",
    "    else:\n",
    "        axs[i // 2, i % 2].set_title(f\"{y}-{y+1}\", fontsize=20)\n",
    "    axs[i // 2, i % 2].scatter(\n",
    "        [year_df[\"longitude\"][i] for i in year_df.index],\n",
    "        [year_df[\"latitude\"][i] for i in year_df.index],\n",
    "        s=3,\n",
    "        c=[colors[year_df[\"party\"][i]] for i in year_df.index],\n",
    "    )\n",
    "    axs[i // 2, i % 2].set_xlim([-180, -60])\n",
    "    axs[i // 2, i % 2].set_ylim([18, 75])\n",
    "    axs[i // 2, i % 2].plot([0], \"r\", label=\"REPUBLICAN\")\n",
    "    axs[i // 2, i % 2].plot([0], \"b\", label=\"DEMOCRAT\")\n",
    "    axs[i // 2, i % 2].legend()\n",
    "\n",
    "    sns.set(font_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Generate a list of 50 random RGBA colors\n",
    "random_colors = [\n",
    "    (random.random(), random.random(), random.random(), random.uniform(0.5, 1.0))\n",
    "    for _ in range(51)\n",
    "]\n",
    "\n",
    "colors = {}\n",
    "state_list = list(joined_df.sort_values(\"state\", ascending=False)[\"state\"].unique())\n",
    "for i, state in enumerate(state_list):\n",
    "    colors[state] = random_colors[i]\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "usa = plt.imread(\"images/NorthAmerica.png\")\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    1,\n",
    "    2,\n",
    "    figsize=(30, 10),\n",
    "    gridspec_kw={\"height_ratios\": [1], \"width_ratios\": [1, 1]},\n",
    ")\n",
    "\n",
    "axs[0].imshow(usa, extent=[-180, -60, 20, 80])\n",
    "axs[0].scatter(\n",
    "    [joined_df[\"longitude\"][i] for i in joined_df.index],\n",
    "    [joined_df[\"latitude\"][i] for i in joined_df.index],\n",
    "    s=1,\n",
    "    c=[colors[joined_df[\"state\"][i]] for i in joined_df.index],\n",
    ")\n",
    "axs[0].set_xlim([-170, -65])\n",
    "axs[0].set_ylim([18, 80])\n",
    "\n",
    "for i, value in enumerate(\n",
    "    joined_df.sort_values(\"state\", ascending=False)[\"state\"].unique()\n",
    "):\n",
    "    count = joined_df.loc[joined_df[\"state\"] == value].shape[0]\n",
    "    axs[1].barh(value, count, color=random_colors[i])\n",
    "\n",
    "axs[1].set_xlabel(\"Number of incidents from Jan 2013 to Mar 2018\")\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poverty percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "usa = plt.imread(\"images/NorthAmerica.png\")\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    1,\n",
    "    2,\n",
    "    figsize=(30, 10),\n",
    "    gridspec_kw={\"height_ratios\": [1], \"width_ratios\": [1, 1]},\n",
    ")\n",
    "\n",
    "axs[0].imshow(usa, extent=[-180, -60, 20, 80])\n",
    "scatter = axs[0].scatter(\n",
    "    [joined_df[\"longitude\"][i] for i in joined_df.index],\n",
    "    [joined_df[\"latitude\"][i] for i in joined_df.index],\n",
    "    s=1,\n",
    "    c=[joined_df[\"povertyPercentage\"][i] for i in joined_df.index],\n",
    ")\n",
    "\n",
    "axs[0].set_xlim([-170, -60])\n",
    "axs[0].set_ylim([18, 80])\n",
    "\n",
    "####\n",
    "\n",
    "states = joined_df.sort_values(\"state\", ascending=False)[\"state\"].unique()\n",
    "incidents_rate = []\n",
    "\n",
    "poverty = []\n",
    "for i, value in enumerate(states):\n",
    "    poverty.append(\n",
    "        np.mean(joined_df.loc[joined_df[\"state\"] == value][\"povertyPercentage\"])\n",
    "    )\n",
    "\n",
    "sorted_indices = np.argsort(poverty)\n",
    "\n",
    "# Use sorted indices to reorder both arrays\n",
    "poverty = [poverty[i] for i in sorted_indices]\n",
    "states = [states[i] for i in sorted_indices]\n",
    "\n",
    "cmap = cm.magma\n",
    "norm = plt.Normalize(min(poverty), max(poverty))\n",
    "colors = cmap(norm(poverty))\n",
    "sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=axs[1], label=\"Poverty percentage\")\n",
    "\n",
    "for i, value in enumerate(states):\n",
    "    count = joined_df.loc[joined_df[\"state\"] == value].shape[0]\n",
    "    population = population_df[\n",
    "        (population_df[\"state\"] == value) & (population_df[\"year\"] == 2018)\n",
    "    ][\"population\"]\n",
    "    incidents_rate.append(count / population * 1e6)\n",
    "    axs[1].barh(value, count / population * 1e6, color=colors[i])\n",
    "\n",
    "axs[1].set_xlabel(\"Number of incidents every million people from Jan 2013 to Mar 2018\")\n",
    "sns.set(font_scale=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\n",
    "    \"date\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"min_age_participants\",\n",
    "    \"avg_age_participants\",\n",
    "    \"max_age_participants\",\n",
    "    \"children_ratio\",\n",
    "    \"teen_ratio\",\n",
    "    \"adults_ratio\",\n",
    "    \"males_ratio\",\n",
    "    \"females_ratio\",\n",
    "    \"killed_ratio\",\n",
    "    \"injured_ratio\",\n",
    "    \"arrested_ratio\",\n",
    "    \"unharmed_ratio\",\n",
    "    \"n_participants\",\n",
    "    \"povertyPercentage\",\n",
    "    \"republicans_ratio\",\n",
    "    \"democrats_ratio\",\n",
    "    \"totalvotes\",\n",
    "    \"dead_murder_or_suicide\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "# Compute the correlation matrix\n",
    "corr = joined_df[numerical_columns].corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    mask=mask,\n",
    "    cmap=cmap,\n",
    "    vmax=0.3,\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={\"shrink\": 0.5},\n",
    ")\n",
    "\n",
    "sns.set(font_scale=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.drop(\"females_ratio\", axis=1, inplace=True)\n",
    "joined_df.drop(\"children_ratio\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = joined_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isna().sum() / joined_df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.get_dummies(final_df, columns=[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.loc[final_df[\"party\"] == \"DEMOCRAT\", \"party\"] = 0\n",
    "final_df.loc[final_df[\"party\"] == \"REPUBLICAN\", \"party\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"month_x\"] = np.sin(final_df[\"month\"] * 2 * np.pi / 12)\n",
    "final_df[\"month_y\"] = np.cos(final_df[\"month\"] * 2 * np.pi / 12)\n",
    "final_df.drop(\"month\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"data/final_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm-1svB9iq5-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
