{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare Time Series Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/final_dataset.csv\")\n",
    "print(\"Shape of dataset:\", dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Select cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only incidents regarding [2014, 2015, 2016, 2017], as by project assignment instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[(dataset['year'] > 2013) & (dataset['year'] < 2018)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of cities reveals that many cities are present with different names, resulting in incorrect city value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('debugging/cities.txt', 'w') as f:\n",
    "    for item in dataset['city_or_county'].unique():\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "# Write city and value counts of each city to a file\n",
    "with open('debugging/city_counts.txt', 'w') as f:\n",
    "    f.write(dataset['city_or_county'].value_counts().to_string())\n",
    "\n",
    "print('There are {} unique cities in the dataset'.format(len(dataset['city_or_county'].unique())))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminate parenthesis with county or extra information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate all data between parenthesis in the city_or_county column using re module\n",
    "dataset['city_or_county'] = dataset['city_or_county'].apply(lambda x: re.sub(r\"\\(.*\\)\", \"\", x))\n",
    "print('There are {} unique cities in the dataset'.format(len(dataset['city_or_county'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort cities alphabetically to see if there are still duplicates and how relevant they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all cities and sort them alphabetically and write them in a file\n",
    "cities = dataset['city_or_county'].unique()\n",
    "cities.sort()\n",
    "with open('debugging/cities2.txt', 'w') as f:\n",
    "    for item in cities:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are many cities which differ in having a space in the end, let's remove all spaces to avoid problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all spaces from city names\n",
    "dataset['city_or_county'] = dataset['city_or_county'].apply(lambda x: x.replace(\" \", \"\"))\n",
    "print('There are {} unique cities in the dataset'.format(len(dataset['city_or_county'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['city_or_county'] = dataset['city_or_county'].str.upper()\n",
    "print('There are {} unique cities in the dataset'.format(len(dataset['city_or_county'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing a week parameter and filtering only cities with a number of weeks with incidents greater than 15% of the total number of the weeks of the 4 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['week'] = \" \"\n",
    "\n",
    "# Date attribute is a progressive integer number, starting from 0\n",
    "# Assign a week number to each date\n",
    "dataset['date'] = dataset['date'] - dataset['date'].min()\n",
    "dataset['week'] = dataset['date'].apply(lambda x: int(x / 7))\n",
    "\n",
    "dropping_threshold = 0.01\n",
    "n_weeks = dataset['week'].max()\n",
    "n_weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = dataset['city_or_county'].unique()\n",
    "\n",
    "for city in cities:\n",
    "    city_data = dataset[dataset['city_or_county'] == city]\n",
    "    city_weeks_with_incidents = city_data['week'].nunique()\n",
    "\n",
    "    # Drop the city if it has less than 15% of the weeks with incidents\n",
    "    if city_weeks_with_incidents < n_weeks * dropping_threshold:\n",
    "        dataset = dataset[dataset['city_or_county'] != city]\n",
    "\n",
    "print('Number of cities for which time series will be generated:', dataset['city_or_county'].nunique())\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Score functions for subtasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the functions to compute the score for each of the two subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_week_score(week_data, task):\n",
    "    # Compute the score for a given week, to be used in the time series\n",
    "    match task:\n",
    "        case 'task1':\n",
    "            score = week_data['n_killed'].sum()\n",
    "        case _:\n",
    "            raise ValueError('Task not recognized')\n",
    "    return score\n",
    "\n",
    "def generate_time_series(city_data, n_weeks, task):\n",
    "    # Generate the time series for a given city\n",
    "    time_series = np.zeros(n_weeks)\n",
    "    for week in range(n_weeks):\n",
    "        week_data = city_data[city_data['week'] == week]\n",
    "        if week_data.shape[0] > 0:\n",
    "            time_series[week] = compute_week_score(week_data, task)\n",
    "    return time_series\n",
    "\n",
    "def generate_time_series_dataset(dataset, task):\n",
    "    # Generate the time series for all cities\n",
    "    n_weeks = dataset['week'].max()\n",
    "    cities = dataset['city'].unique()\n",
    "    time_series = []\n",
    "    for city in cities:\n",
    "        city_data = dataset[dataset['city'] == city]\n",
    "        time_series.append(generate_time_series(city_data, n_weeks, task))\n",
    "    return np.array(time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clustering and Motif/Anomalies Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Generate time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dataset = generate_time_series_dataset(dataset, 'task1')\n",
    "ts_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
