{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/final_dataset.csv\")\n",
    "print(\"Shape of dataset:\", dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are NaN values:\", dataset.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_columns = [c for c in dataset.columns if c.startswith('state_')]\n",
    "dropped_columns += ['min_age_participants', 'max_age_participants', 'teen_ratio', 'totalvotes']\n",
    "print(\"Attributes to drop:\", dropped_columns)\n",
    "dataset_reduced = dataset.drop(columns=dropped_columns, axis = 1)\n",
    "print(\"Shape of dataset:\", dataset_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_dataset = dataset_reduced._get_numeric_data()\n",
    "print(\"Shape of numeric_dataset:\", numeric_dataset.shape)\n",
    "numeric_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = dataset_reduced.boxplot(column=['povertyPercentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = dataset_reduced.boxplot(column = ['avg_age_participants', 'n_participants'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = dataset_reduced.boxplot(column = ['adults_ratio', 'males_ratio', 'killed_ratio', 'injured_ratio', 'arrested_ratio', 'votes_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = dataset_reduced.boxplot(column = ['party'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = dataset_reduced.boxplot(column = ['totalvotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot = dataset_reduced.boxplot(column = [ 'population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_dataset = scaler.fit_transform(numeric_dataset.values)\n",
    "scaled_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. K Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Identification of the best value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse_list = []\n",
    "silhouette_list = []\n",
    "davies_bouldin_list = []\n",
    "\n",
    "max_k = 20\n",
    "for k in tqdm(range(2, max_k + 1), ):\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10)\n",
    "    kmeans.fit(scaled_dataset)\n",
    "\n",
    "    sse_list.append(kmeans.inertia_)\n",
    "    silhouette_list.append(silhouette_score(scaled_dataset, kmeans.labels_, sample_size=10000))\n",
    "    davies_bouldin_list.append(davies_bouldin_score(scaled_dataset, kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(20, 15))\n",
    "ax[0].plot(range(2, len(sse_list) + 2), sse_list)\n",
    "ax[0].set_ylabel('SSE', fontsize=22)\n",
    "ax[0].set_xticks(range(2, len(sse_list) + 2))\n",
    "\n",
    "ax[1].plot(range(2, len(silhouette_list) + 2), silhouette_list)\n",
    "ax[1].set_ylabel('Silhouette Score', fontsize=22)\n",
    "ax[1].set_xticks(range(2, len(silhouette_list) + 2))\n",
    "\n",
    "ax[2].plot(range(2, len(davies_bouldin_list) + 2), davies_bouldin_list)\n",
    "ax[2].set_ylabel('Davies Bouldin Score', fontsize=22)\n",
    "ax[2].set_xticks(range(2, len(davies_bouldin_list) + 2))\n",
    "\n",
    "\n",
    "plt.xlabel('K', fontsize=22)\n",
    "plt.show()\n",
    "\n",
    "# NICER PLOTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Analysis of the centroids and clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=10)\n",
    "kmeans.fit(scaled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of scaled_dataset: \", scaled_dataset.shape)\n",
    "print(\"Shape of kmeans.labels_: \", kmeans.labels_.shape)\n",
    "print(\"Shape of kmeans.cluster_centers_: \", kmeans.cluster_centers_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "centers_df = pd.DataFrame(centers, columns=numeric_dataset.columns)\n",
    "centers_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_num_points = []\n",
    "cluster_points = []\n",
    "for i in range(n_clusters):\n",
    "    cluster_points.append(scaled_dataset[kmeans.labels_ == i])\n",
    "    cluster_num_points.append(len(cluster_points[-1]))\n",
    "    \n",
    "cluster_num_points, cluster_points[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_tot = KMeans(n_clusters=1, n_init=10)\n",
    "kmeans_tot.fit(scaled_dataset)\n",
    "total_SSE = kmeans_tot.inertia_ / len(scaled_dataset)\n",
    "\n",
    "cluster_SSE = []\n",
    "for i in range(n_clusters):\n",
    "    cluster_sse = 0\n",
    "    for point in cluster_points[i]:\n",
    "        cluster_sse += np.linalg.norm(point - kmeans.cluster_centers_[i])**2\n",
    "    cluster_SSE.append(cluster_sse / cluster_num_points[i])\n",
    "\n",
    "print(\"Cluster SSE: \", cluster_SSE)\n",
    "print(\"Total SSE: \", total_SSE)\n",
    "print(\"SSE of cluster with min SSE: \", min(cluster_SSE))\n",
    "print(\"SSE of cluster with max SSE: \", max(cluster_SSE))\n",
    "print(\"Mean of SSE: \", np.mean(cluster_SSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_distance_variance = []\n",
    "total_distance_variance = 0\n",
    "dataset_centroid = np.mean(scaled_dataset, axis=0)\n",
    "\n",
    "###### CI RIPENSIAMO SU QUESTO ######\n",
    "for point in scaled_dataset:\n",
    "    total_distance_variance += (np.linalg.norm(point - dataset_centroid)**2 - total_SSE) ** 2\n",
    "total_distance_variance /= len(scaled_dataset)\n",
    "#####################################\n",
    "\n",
    "for i in range(n_clusters):\n",
    "    variance = 0\n",
    "    for p in cluster_points[i]:\n",
    "        variance += ((np.linalg.norm(p - kmeans.cluster_centers_[i]))**2 - cluster_SSE[i])**2\n",
    "    cluster_distance_variance.append(variance/cluster_num_points[i])\n",
    "\n",
    "print(\"Cluster distance variance: \", cluster_distance_variance)\n",
    "print(\"Total distance variance: \", total_distance_variance)\n",
    "print(\"Distance variance of cluster with min SSE: \", min(cluster_distance_variance))\n",
    "print(\"Distance variance of cluster with max SSE: \", max(cluster_distance_variance))\n",
    "print(\"Mean of distance variance: \", np.mean(cluster_distance_variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of distribution of repubblican vs democrats in the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_xt_pct = pd.crosstab(kmeans.labels_, numeric_dataset['party'])\n",
    "party_xt_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_xt_pct.plot(kind='bar', stacked=False, \n",
    "                   title='Party per cluster')\n",
    "plt.xlabel('Cluster')\n",
    "plt.ylabel('Party')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a distance matrix among cluster centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_distance_matrix = squareform(pdist(kmeans.cluster_centers_))\n",
    "sns.heatmap(centroid_distance_matrix, annot=True, fmt = '.2f', cmap='crest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct matrix displaying correlation of attribute values to belonging to a certain cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom kmeans labels into onehot encoding\n",
    "onehot = np.zeros((len(kmeans.labels_), n_clusters))\n",
    "onehot[np.arange(len(kmeans.labels_)), kmeans.labels_] = 1\n",
    "\n",
    "# Compute correlation between onehot encoding and scaled dataset\n",
    "onehot_corr = np.corrcoef(scaled_dataset, onehot, rowvar=False)\n",
    "\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "sns.heatmap(onehot_corr[:scaled_dataset.shape[1], scaled_dataset.shape[1]:], cmap=cmap)\n",
    "\n",
    "# Set ticks on y axis with feature names\n",
    "plt.yticks(np.arange(scaled_dataset.shape[1]) + 0.5, numeric_dataset.columns, rotation=0, fontsize=12)\n",
    "[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the similarity matrix of a sample of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the dataset to 10000\n",
    "samples = np.random.choice(scaled_dataset.shape[0], 1000, replace=False)\n",
    "downsampled_dataset = scaled_dataset[samples]\n",
    "downsampled_labels = kmeans.labels_[samples]\n",
    "\n",
    "# Sort based on labels\n",
    "sorted_indexes = np.argsort(downsampled_labels)\n",
    "downsampled_dataset = downsampled_dataset[sorted_indexes]\n",
    "downsampled_labels = downsampled_labels[sorted_indexes]\n",
    "\n",
    "# Compute similarity matrix\n",
    "pdist_matrix = squareform(pdist(downsampled_dataset, metric='minkowski', p=2))\n",
    "sns.heatmap(pdist_matrix, fmt = '.2f', cmap='crest')\n",
    "plt.xticks([])\n",
    "plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, n_jobs=-1)\n",
    "tsne_dataset = np.concatenate((downsampled_dataset, kmeans.cluster_centers_))\n",
    "tsne_labels = np.concatenate((downsampled_labels, range(7)))\n",
    "tsne_map = tsne.fit_transform(tsne_dataset)\n",
    "\n",
    "plt.scatter(tsne_map[:-n_clusters, 0], tsne_map[:-n_clusters, 1], c = tsne_labels[:-n_clusters], s=10, cmap='tab10')\n",
    "plt.scatter(tsne_map[-n_clusters:, 0], tsne_map[-n_clusters:, 1], c = tsne_labels[-n_clusters:], s=100, cmap='tab10', marker='*', edgecolors='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Distribution of variables: within clusters vs whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans.labels_.shape)\n",
    "print(numeric_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of average age for whole dataset and clusters\n",
    "numeric_dataset_with_clusters = numeric_dataset.copy()\n",
    "numeric_dataset_with_clusters['cluster'] = kmeans.labels_\n",
    "\n",
    "sns.displot(numeric_dataset_with_clusters, x=\"avg_age_participants\", kind='kde', hue=\"cluster\")\n",
    "\n",
    "sns.displot(numeric_dataset_with_clusters, x=\"males_ratio\", kind='kde', hue=\"cluster\")\n",
    "\n",
    "# Stretch horizontally\n",
    "plt.gcf().set_size_inches(20, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(numeric_dataset_with_clusters, x=\"povertyPercentage\", y='n_participants', hue=\"cluster\")\n",
    "plt.ylim(0,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(numeric_dataset_with_clusters, x=\"povertyPercentage\", y='n_participants', kind='kde', hue=\"cluster\")\n",
    "# Restric the plot to number of participants between 0 and 30\n",
    "plt.ylim(0, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numeric_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(numeric_dataset['longitude'], numeric_dataset['latitude'],  c=kmeans.labels_, s=20)\n",
    "plt.scatter(centers_df['longitude'], centers_df['latitude'], marker='*', c='r', s=150)\n",
    "#plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Clustering Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
